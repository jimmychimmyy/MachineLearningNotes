# Bias-Variance Tradeoff

The bias-variance tradeoff in machine learning is a property of machine learning where models with high bias have low variance, and models with low bias have high variance.

#### What is Bias?

Bias is error that is a result of assumptions made by the machine learning algorithm.

High bias will cause the algorithm to [underfit]() the data.

High bias algorithms are usually less complex
* Linear Algorithms
* Parametric Algorithms

#### What is Variance?

Variance is error from noise in the training data.

High variance will cause the algorithm to [overfit]() the data.

High variance algorithms are usually more complex
* Non-linear Algorithms
* Non-parametric Algorithms

#### Why do we want to minimize both bias and variance?

We want to minimize both bias and variance because


#### How do we actually achieve low bias and variance?

We need to find a balance of bias and variance that minimizes total error.

#### Sources
1. https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff
2. https://elitedatascience.com/bias-variance-tradeoff
