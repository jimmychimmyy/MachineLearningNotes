{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Tree():\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_classes = len(set(self.y))\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def cost_function_entropy(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    # assumes all feature values are continuous\n",
    "    def cost_function_gini(self, subset, n_classes=2):\n",
    "        total_instances = sum(len(s) for s in subset)\n",
    "        gini = 0\n",
    "        for s in subset:\n",
    "            size = len(s)\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0\n",
    "            for label in n_classes:\n",
    "                probability = [row[-1] for row in subset].count(label)\n",
    "                probability /= size\n",
    "                score += p **2\n",
    "            gini += (1 - score) * (size/total_instances)\n",
    "        return gini\n",
    "        \n",
    "    # assumes all feature values are discrete\n",
    "    def compute_information_gain(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def test_split(self, df, index, split_value):\n",
    "        left = list()\n",
    "        right = list()\n",
    "        for instance in df:\n",
    "            if instance[index] < split_value:\n",
    "                left.append(instance)\n",
    "            else:\n",
    "                right.append(instance)\n",
    "        return left, right\n",
    "        \n",
    "    def split(self, dataset):\n",
    "        labels = self.y\n",
    "        best_index = 100\n",
    "        best_value = 100\n",
    "        best_score = 100\n",
    "        best_subsets = None\n",
    "        for index in range(len(dataset[0]) - 1):\n",
    "            for instance in dataset:\n",
    "                subsets = test_split(dataset, index, instance[index])\n",
    "                gini = cost_function_gini(subsets, self.n_classes)\n",
    "                if gini < best_score:\n",
    "                    best_index = index\n",
    "                    best_value = instance[index]\n",
    "                    best_score = gini\n",
    "                    best_subsets = subsets\n",
    "        return {'index':best_index, 'value':best_value, 'subsets':best_subsets}\n",
    "        \n",
    "    def predict(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def train(self, cost=\"gini\"):\n",
    "        if cost == \"gini\":\n",
    "            raise NotImplementedError\n",
    "        elif cost == \"entropy\":\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using iris dataset from https://www.kaggle.com/uciml/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    df = pd.read_csv(\"iris.csv\")\n",
    "    df = df.dropna()\n",
    "    df = df.drop(['Id'], axis=1)\n",
    "    df = df[df['Species'] != 'Iris-versicolor'] # doing this to make it a binary classification problem\n",
    "    print(df.head(), \"\\n\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        print(col, df[col].nunique())\n",
    "    \n",
    "    # map species to ints\n",
    "    df.loc[df['Species'] == 'Iris-virginica', 'Species'] = 0\n",
    "    df.loc[df['Species'] == 'Iris-setosa', 'Species'] = 1\n",
    "    \n",
    "    # split train test\n",
    "    y = df.as_matrix(columns=['Species'])\n",
    "    X = df.drop(['Species'], axis=1).as_matrix()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.2, random_state=42)\n",
    "    \n",
    "    clf = Decision_Tree(X_train, y_train)\n",
    "    clf.train()\n",
    "    \n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
